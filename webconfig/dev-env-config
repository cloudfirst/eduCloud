~/.bashrc

export JAVA_HOME=/usr/local/jre1.6.0_24
export DEB_BUILD_OPTIONS="nostrip noopt"
alias educlient_clean='cd /mnt/src/educloud-client && rm *.deb *.zip *.changes *.dsc *.tar.gz && cd /mnt/src/educloud-client/src/debian && rm -fr educloud-vdi-client/ educloud-client-for-win/ educloud-client/ educloud-native-client/ unplug-daemon/ && rm *.log *.substvar* *.debhelper* stamp* compat files'
alias educlean='cd /mnt/src/ && rm *.deb *.dsc *.tar *.tar.gz *.changes && cd /mnt/src/eduCloud/debian && rm -fr educloud-core/ educloud-webbase/ educloud-cc/ educloud-walrus/ educloud-clc/ educloud-portal/ educloud-virtapp/ nodedaemon-cc/ nodedaemon-clc/ nodedaemon-nc/ nodedaemon-tnc/ nodedaemon-walrus/ && rm *.log *.substvars *.debhelper stamp* compat files && cd /mnt/src/eduCloud/nodeDaemon && rm cc/cc_daemon.spec clc/clc_daemon.spec nc/nc_daemon.spec walrus/walrus_daemon.spec tnc/tnc_daemon.spec ../webconfig/piplib/3rd/luhyaapi-1.1.tar.gz ../webconfig/piplib/3rd/rsync-3.1.0/config.guess.cdbs-orig ../webconfig/piplib/3rd/rsync-3.1.0/config.sub.cdbs-orig && cd /mnt/src/eduCloud && cd /mnt/src/eduCloud/nodeDaemon && rm -fr clc/build clc/dist walrus/build walrus/dist cc/build cc/dist nc/build nc/dist tnc/dist tnc/build'
alias publish2debian='scp /mnt/src/*.deb root@192.168.56.102:/root/Downloads/ && scp /mnt/src/eduCloud/webconfig/product/*.py root@192.168.56.102:/var/packages/scripts/ && scp /mnt/src/pip.tar root@192.168.56.102:/var/packages/'
alias publish='scp /mnt/src/*.deb root@121.41.80.147:/root/Downloads/ && scp /mnt/src/eduCloud/webconfig/product/*.py root@121.41.80.147:/var/packages/scripts/ && scp /mnt/src/pip.tar root@121.41.80.147:/var/packages/'
alias publish2client='scp /mnt/src/educloud-client/*.deb 192.168.56.102:/home/luhya/Downloads/client/ && scp /mnt/src/educloud-client/src/scripts/*.py 192.168.56.102:/var/packages/scripts/client/'
alias publish_client='scp /mnt/src/educloud-client/*.deb root@121.41.80.147:/root/Downloads/client/ && scp /mnt/src/educloud-client/src/scripts/*.py root@121.41.80.147:/var/packages/scripts/client/'

sudo apt-get install git git-core openssh-server dpkg dpkg-dev python-pip quilt
pip install PyInstaller


python ../manage.py makemessages -l zh_CN
python ../manage.py compilemessages

working flow for virtual desktop:
startVD
---tid=" " => client:create_tvd("/clc/api/1.0/rvd/create/s") => client:prepare_tvd("/clc/api/1.0/rvd/prepare/s/d/i") => client:run_tvd("/clc/api/1.0/rvd/run/s/d/i") => client:stop_tvd(tid)
               server:rvd_create()                               server:rvd_prepare()                                    server:rvd_run()                                TVD:   delete_task(tid) "/clc/api/1.0/tasks/delete"
               --- insid = TVD+random                            --- image_create_task_prepare()                         --- image_create_task_run()                     server:delete_tasks()/delet_task_by_id() "cc/api/1.0/task/delete'"
               --- findBuildResource()                                                                                                                                   VD:    stop_task(tid)  "/clc/api/1.0/rvd/stop/"
               --- gen Runtime option                                                                                                                                    server:rvd_stop()/image_create_task_stop()
               --- create Transaction record
---tid="x"  => client:start_tvd("/clc/api/1.0/rvd/start/s/d/i")     => client:prepare_tvd("/clc/api/1.0/rvd/prepare/s/d/i") => client:run_tvd("/clc/api/1.0/rvd/run/s/di") => client:stop_tvd()
               server:rvd_start()                                server:rvd_prepare()
                --- findVMRunningResource                        --- image_create_task_prepare()
                --- update Transaction phase/state, ccip/ncip
                --- gen Runtime option
                for both TVD and VD


working flow for image build/modify:
prepareVM() -- "/clc/image/create/task/prepare/srcid/dstid/insid"   image_create_task_prepare()
                                                                    --- update phase/state
                                                                    --- call cc/api/1.0/image/create/task/prepare
runVM()     -- "/clc/image/create/task/run/srcid/dstid/insid"       image_create_task_run()
                                                                    --- update phase/state
                                                                    --- call cc/api/1.0/image/create/task/run
stopVM()    -- "/clc/image/create/task/stop/srcid/dstid/insid"      image_create_task_stop()
                                                                    --- update phase/state
                                                                    --- call cc/api/1.0/image/create/task/stop

VM启动关闭消息流分析
启动：
1. client http request 到 clc 的rvd_create()或者rvd_start(),查找可用资源
2. client http request 到 clc 的rvd_prepare()->image_create_task_prepare()
   clc http request 到 cc 的 image_create_task_prepare()
   cc 发送 zmq 消息 image/prepare 到 nc 的 nc_image_prepare_handle()  # nc_cmd_consumer 一直循环等待zmq消息
   nc 启动 prepareImageTaskThread 进程
      image  downloadFromWalrus2CC()
             downloadFromCC2NC()
             cloneImage()
      data   downloadFromWalrus2CC()
             cloneImage()
      rpc 消息 "image/prepare/success" 给 cc 的 cc_rpc_handle_prepare_success()—>prepareImageFinished()
          prepareImageFinished()发送http request给clc的image_create_task_prepare_success()
          clc更新ectaskTransaction数据库为"preparing/done"
      amqp message "taskstatus : preparing/done" 给cc的 "cc_status_queue"
          cc通过amqp转发消息给clc的“clc_status_queue”
             clc把收到的消息存到memcahe里面
#################
UPGRADE SOLUTION
#################
- 去掉全局rpc消息和amqp消息
- 替换为nc发送http post消息"taskstatus : preparing/done" 给cc, cc转发给clc, clc更新db和memcache
  clc收到post消息后更新memcache和db
- nc只有收到200结果后才会停止更新

3 client http request 到 clc 的 rvd_run()->image_create_task_run()
  clc http request 到 cc 的 image_create_task_run()
  cc 发送 zmq 消息 'image/run' 到 nc
  nc 启动 runImageTaskThread 进程
      creatvm() -> vbox_createVM() -> “taskstatus：edit/booting”消息通过amqp发送给cc，再转发到clc
      runvm()   -> vbox_runVM()    -> “taskstatus：edit/running”消息通过amqp发送给cc，再转发到clc
      rpc ‘image/edit/running’ 消息给 cc 的 cc_rpc_handle_image_running()
          updateVMStatus()发送http request给clc的image_create_task_updatevmstatus()
          clc更新ectaskTransaction数据库为新的vmstate=running
      amqp 更新 nc 的 status report
#################
UPGRADE SOLUTION
#################
- vbox_createVM()后
  把amqp消息替换为nc发送http post消息"taskstatus : edit/booting" 给cc, cc转发给clc，clc更新db和memcache
  nc只有收到200结果后才会停止更新
- vbox_runVM()后
  把amqp消息替换为nc发送http post消息"taskstatus : edit/running" 给cc, cc转发给clc，clc更新db和memcache
  nc只有收到200结果后才会停止更新
- 去掉全局的rpc消息和amqp消息

4. client http request 到 clc 的  delete_tasks()/rvd_stop()
   clc->delete_tasks()->delet_task_by_id() 发送 http request 到 cc 的 delete_tasks()， #然后删除ectaskTransaction中的记录
       cc 发送 zmq 消息 'task/delete' 到 nc 的 nc_task_delete_handle()
          nc 启动 DeleteImageTaskThread 进程
            调用 process_delete_cmd()
                调用process_stop_cmd()
                vboxmgr.unregisterVM()
                vboxmgr.deleteVMConfigFile()
                清除vbox的medium
                删除vm的临时目录
            调用 update_nc_running_status() 通过 amqp 机制更新nc的状态
   clc->rvd_stop()->image_create_task_stop() 发送 http request 到 cc 的 image_create_task_stop(), #然后更新ectaskTransaction中的记录
       cc 发送 zmq 消息 'image/stop' 到 nc 的 nc_image_stop_handle()
          nc 启动 StopImageTaskThread 进程
            调用 process_stop_cmd()
                pkill ndp 进程 或者 vbox poweroff
                发送amqp消息taskstatus:editing/stopped到cc
                恢复快照
#################
UPGRADE SOLUTION
#################
- clc发送http request到cc，确保反馈为200
- cc发送zmq消息给nc，确保反馈为OK
- nc取消发送amqp消息，改为向cc发送http request消息taskstatus:editing/stopped|deleted，cc转发给clc，clc更新db和memcache

5. 检测到有vm关机了，发送'ndp/stop'消息给nc_cmd_consumer->nc_ndp_stop_handle()->update_nc_running_status(external msg)
   发送amqp消息nodestatus到cc的cc_status_queue，然后转发到clc的clc_status_queue
   clc在处理nodestatus消息是，查找external部分的ndp/stop消息，调用ndpStopCLCWrapper，http request到clc的image_ndp_stop()
     调用delet_task_by_id()/image_create_task_stop()
#################
UPGRADE SOLUTION
#################
- 取消amqp消息
- nc收到“ndp/stop"消息后，发送zmq消息给cc，然后cc发送zmq消息给clc
- clc daemon发送http request给clc（等同于模拟客户点击Stop按钮）
- 回到delete_tasks()/rvd_stop()的处理


########################################################
这里的重点是确保
- preparing/done
- edit/running
- edit/stopped
这三条消息能够及时更新到clc的memcache上，无论负载有多大。

clc-->http-->cc-->zmq-->nc
  return code == 200, 否则尝试10次
nc-->zmq-->cc-->http-->clc
  recv到OK的确认，否则尝试10次
########################################################

for VD and PVD,
admin create a concept, assign to user
user instantiate it to run

for TMP
start:   create vm, take snapshot, run
stop:    power off
restart: run
stop:    power off
delete:  delete transaction, stop, unregister, delete config, delete image

for TVD:
 start:   create vm,  run
#stop:    power off, restore-snapshot
 restart: run
#stop:    power off, restore-snapshot
 delete:  delete transaction, stop, unregister, delete config

for VD:
 start:   create vm,  run
#stop:    power off, restore-snapshot
 restart: run
#stop:    power off, restore-snapshot
 delete:  delete transaction, stop, unregister, delete config

for PVD: (c disk writethrough)
 start:   create vm,  run
 stop:    power off
 restart: run
 stop:    power off
#delete:  delete transaction, stop, unregister, delete config

disk c: /storage/pimages/uid/imgid/machine

for VS:
???

==========================================
VM Post-boot Event Handle Designe
==========================================
VMHOSTNAME = user+ccname+ncip[3]+vmip[3]

Description:
there os a program that will be executed after windows VM booting,
and this program will do following:
- read the MAC address
- post MAC address to clc
- get back the runtime_option, include hostname, new IP address
- rewrite the host name,
- reconfigure the IP adress

Impelmentation
- based on POST mac address, clc generate a python script, which will be transfer to the vm and run in it
- based on POST mac address, vm python script will do all the work based on http response.


Extra Consideration: binding account, IP and MAC
Solution 1: clc maintain a table on each cluster.
Solution 2: clc query the IP and MAC by account ( ask for CC, whatever implementation it should be )

CC property:
I not bind between account/IP(DHCP)/MAC(random)
    ACMBinging = 0
    - random gen MAC, and{ tid, mac}
II binding IP(static)/MAC(random)
    ACMBinding = 1
    - random gen MAC, and {tid, IP, MAC}
II binding account/IP/MAC  # use rules to
    ACMBinding = 2
    - prepae {account, IP, MAC}
    - and {tid, {a, ip, mac}}

reference :
class ecCCResources(models.Model):
    ccmac0              = models.CharField(max_length=20)
    ccname              = models.CharField(max_length=100)
    cc_usage            = models.CharField(max_length=20) #lvd, rvd, vss, app

    # below are necessary for vds
    rdp_port_pool_def   = models.CharField(max_length=100) # port1-port2
    rdp_port_pool_list  = models.TextField()  # [port1, port2, port3, ... ... ]
    used_rdp_ports      = models.TextField()  # [port1, port2, ports, ... ... ]

    network_mode        = models.CharField(max_length=20) # default = flat, or tree

    # valid only if usage is vs, app
    dhcp_service        = models.CharField(max_length=20) # default = public, or private
    # valid only if dhcp service is private and cc_usage is vs, or app
    dhcp_pool_def       = models.CharField(max_length=100) # port1-port2
    dhcp_interface      = models.CharField(max_length=20)  # default is cc's eth0

    # valid only if network_mode is tree and cc_usage is vs, app
    # all these pub ip will be configured on cc's network card, say eth0.0, eth0.1, etc
    # and followed by iptable rule to redirect traffic on this interface to nc's vm's web_ip
    pub_ip_pool_def   = models.CharField(max_length=100)
    pub_ip_pool_list  = models.TextField()
    used_pub_ip       = models.TextField()

    #valid account, ip, mac bingding for rvd
    ACMBinging = 0, 1, 2





    ================================================================

    binding type = 0 : random gen MAC, and{ tid, mac}
        account  = active user
        ipaddr   = DHCP - NAT/Bridge
        mac      = random generated
        tid      = TMPxxxx, VDxxxx, PVDxxx
    dynamically insert/delete record when power on/off

    binding type = 1 : random gen MAC, and {tid, IP, MAC}
        acount   = active user
        ipaddr   = randomly selected from IP pool
        mac      = randomly selected from mac pool
        tid      = TMPxxx, VDxxx, PVDxxx
    dynamicall insert/delete record when power on/off

    binding type = 2 : {tid, {a, ip, mac}}
        account  = active user
        ipaddr   = select IP by account
        mac      = select IP by account
        tid      = TMPxxx, VDxxx, PVDxxx

    type 0 : no need pool  or a  service return a mac without any input
    type 1 : need a pool (IP, MAC) or a service return {IP, MAC} without any input
    type 2 : need a pool (account, IP, MAC) or a service {IP, MAC} with input account

    process description:
    =======================================
    when cc/nc is selected, clc will generate the runtime_option for this instance.
    based on cc's ACMBingind property
    0: clc will call the service of this cc to get new mac address and store mac in tid
    1: clc will call the service of this cc to get {IP, MAC} pair and store mac in tid
    2: clc will call the service of this cc to get {IP, MAC} pair by account and store mac in tid

    implememtation
    ===============================================
    design a new django app say busirule, to handle all above process
    1. account/ip/mac setting rule before running vm
    2. images filtering rule before display
    3. ... ...
